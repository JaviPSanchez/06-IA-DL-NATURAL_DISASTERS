{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Disaster.PNG\" alt=\"DISASTER LOGO\" />\n",
    "\n",
    "# Natural Language Processing with Disaster Tweets\n",
    "\n",
    "## Project üöß\n",
    "\n",
    "Welcome to one of our \"Getting Started\" competitions üëã\n",
    "This particular challenge is perfect for data scientists looking to get started with Natural Language Processing. The competition dataset is not too big, and even if you don‚Äôt have much personal computing power, you can do all of the work in our free, no-setup, Jupyter Notebooks environment called Kaggle Notebooks.\n",
    "\n",
    "## Projects's Description üìá\n",
    "\n",
    "Twitter has become an important communication channel in times of emergency.\n",
    "The ubiquitousness of smartphones enables people to announce an emergency they‚Äôre observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n",
    "\n",
    "But, it‚Äôs not always clear whether a person‚Äôs words are actually announcing a disaster. Take this example:\n",
    "\n",
    "<img src=\"./Disaster2.PNG\" alt=\"DISASTER LOGO\" />\n",
    "\n",
    "The author explicitly uses the word ‚ÄúABLAZE‚Äù \"en llamas/ ardiendo\" but means it metaphorically. This is clear to a human right away, especially with the visual aid. But it‚Äôs less clear to a machine.\n",
    "\n",
    "In this competition, you‚Äôre challenged to build a machine learning model that predicts which Tweets are about real disasters and which one‚Äôs aren‚Äôt. You‚Äôll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we've created a quick tutorial to get you up and running.\n",
    "\n",
    "Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.\n",
    "\n",
    "\n",
    "## Goals üéØ\n",
    "\n",
    "The project can be divided into three steps:\n",
    "\n",
    "- Part 1 : make an EDA and all the necessary preprocessings to prepare data for machine learning / deep learning\n",
    "- Part 2 : train a **Word Embeding** \n",
    "- Part 3 : **Text Classification**\n",
    "- Part 4 : **Encoder Decoder**\n",
    "- Part 5 : **Attention**\n",
    "\n",
    "## Submission File üñºÔ∏è\n",
    "\n",
    "<img src=\"./Disaster3.PNG\" alt=\"DISASTER LOGO\" />\n",
    "\n",
    "For each ID in the test set, you must predict 1 if the tweet is describing a real disaster, and 0 otherwise. The file should contain a header and have the following format:. ü§ì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tensorflow & Pathlib librairies\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import os\n",
    "import io\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "display(dataset.head(2))\n",
    "display(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Birmingham', 'Est. September 2012 - Bristol', ...,\n",
       "       'Vancouver, Canada', 'London ', 'Lincoln'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
       "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
       "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
       "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
       "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
       "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
       "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
       "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
       "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
       "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
       "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
       "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
       "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
       "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
       "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
       "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
       "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
       "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
       "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
       "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
       "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
       "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
       "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
       "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
       "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
       "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
       "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
       "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
       "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
       "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
       "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
       "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
       "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
       "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
       "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
       "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
       "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
       "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
       "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
       "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
       "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['keyword'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'en_core_news_md'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b605e9e19722>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import Spacy and english initialisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0men_core_news_md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0men_core_news_md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'en_core_news_md'"
     ]
    }
   ],
   "source": [
    "# Import Spacy and english initialisation\n",
    "import en_core_news_md\n",
    "nlp = en_core_news_md.load()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93d4e3805b10e214ea3b1dff9e53d32cf6550b97e339216dbce17f82962eac07"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
